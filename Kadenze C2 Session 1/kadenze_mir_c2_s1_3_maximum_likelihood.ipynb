{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models and likelihood \n",
    "\n",
    "### George Tzanetakis, University of Victoria \n",
    "\n",
    "In this notebook we will introduce the idea of a model and how we can calculate the likelihood of a model given some data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A random variable class \n",
    "\n",
    "Define a helper random variable class based on the scipy discrete random variable functionality providing both numeric and symbolic RVs. You don't need to look at the implementation - the usage will be obvious through the examples below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "\n",
    "class Random_Variable: \n",
    "    \n",
    "    def __init__(self, name, values, probability_distribution): \n",
    "        self.name = name \n",
    "        self.values = values \n",
    "        self.probability_distribution = probability_distribution \n",
    "        if all(type(item) is np.int_ for item in self.values): \n",
    "            self.type = 'numeric'\n",
    "            self.rv = stats.rv_discrete(name = name, \n",
    "                        values = (values, probability_distribution))\n",
    "        elif all(type(item) is str for item in values): \n",
    "            self.type = 'symbolic'\n",
    "            self.rv = stats.rv_discrete(name = name, \n",
    "                        values = (np.arange(len(values)), probability_distribution))\n",
    "            self.symbolic_values = values \n",
    "        else: \n",
    "            self.type = 'undefined'\n",
    "            \n",
    "    def sample(self,size): \n",
    "        if (self.type =='numeric'): \n",
    "            return self.rv.rvs(size=size)\n",
    "        elif (self.type == 'symbolic'): \n",
    "            numeric_samples = self.rv.rvs(size=size)\n",
    "            mapped_samples = [self.values[x] for x in numeric_samples]\n",
    "            return mapped_samples \n",
    "        \n",
    "    def prob_of_value(self, value): \n",
    "        indices = np.where(self.values == value)\n",
    "        return self.probability_distribution[indices[0][0]]\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by creating a random variable corresponding to a 6-faced dice where there are two faces with the numbers 1,2 and 3 therefore each number appears with equal probability. We can generate random samples from this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 3 2 1 1 1 1 3 2 2 2 1 2 2 2 3 1 3 2 1 1 3 3 2 1 2 3 1 1]\n"
     ]
    }
   ],
   "source": [
    "values = np.int64([1, 2, 3])\n",
    "probabilities = [2/6., 2/6., 2/6.]\n",
    "dice1 = Random_Variable('dice1', values, probabilities)\n",
    "samples = dice1.sample(30)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also create a random variable where three of the faces have the number 2, 2 faces have the number 1 and 1 face has the number 3. We can also generate random samples from this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 2 1 1 2 2 2 3 2 3 1 2 2 2 1 2 2 2 2 2 2 2 2 3 2 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "values = np.int_([1, 2, 3])\n",
    "probabilities = [2./6, 3./6, 1./6]\n",
    "dice2 = Random_Variable('dice2', values, probabilities)\n",
    "samples = dice2.sample(30)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood of a sequence of samples given a model can be obtained by taking the product of the corresponding \n",
    "probabilities. We can see that for this particular sequence of data the likelihood of the model for dice2 is higher. So if we have some data and some specific models we can select the model with the highest likelihood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "0.3333333333333333\n",
      "0.16666666666666666\n",
      "Likelihood for dice1: 0.000017\n",
      "Likelihood for dice2: 0.000021\n"
     ]
    }
   ],
   "source": [
    "data = [1,2,2,1,1,3,1,2,3,2]\n",
    "print(dice1.prob_of_value(1))\n",
    "print(dice1.prob_of_value(3))\n",
    "print(dice2.prob_of_value(3))\n",
    "\n",
    "def likelihood(data, model):\n",
    "    likelihood = 1.0 \n",
    "    for d in data: \n",
    "        likelihood *= model.prob_of_value(d)\n",
    "    return likelihood \n",
    "    \n",
    "print(\"Likelihood for dice1: %f\" % likelihood(data,dice1))\n",
    "print(\"Likelihood for dice2: %f\" % likelihood(data,dice2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the case above we examined two possible models. One could ask the question of all possible models for a particular problem can we find the one with the highest likelihood ? If we have a dice with six faces that can only have the number 1, 2, and 3 then there is a finite amount of models and we can calculate their likelihoods as we did above. However if we relax the requirement to have a dice and simply have the values 1,2 and 3 but with arbitrary associated probabilities then we have an infinte number of possible models. Without going into the math it turns out that at least for this particular case the model that will have the maximum likelihood can be simply obtained by counting the relative frequencies of the values in the data. This is called maximum likelihood estimation of model parameters and is something we will revisit later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 4, 2: 4, 3: 2})\n",
      "[0.4, 0.4, 0.2]\n"
     ]
    }
   ],
   "source": [
    "import collections \n",
    "\n",
    "data = [1,2,2,1,1,3,1,2,3,2]\n",
    "counts = collections.Counter(data)\n",
    "print(counts)\n",
    "est_probability_distribution = [counts[1]/float(len(data)), counts[2]/float(len(data)), counts[3]/float(len(data))]\n",
    "print(est_probability_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this approach to create a new model from this data and generate new samples. \n",
    "When using probabilistic models in machine learning, we use data to estimate the parameters \n",
    "of typically much more complex models (training) and then use those models to estimate probabilities and likelihoods for other sets of data (testing). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 2 1 1 1 1 1 2 1 3 3 1 1 1 1 2 2 1 1 1 2 2 1 3 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "values = np.int_([1, 2, 3])\n",
    "probabilities = est_probability_distribution \n",
    "model = Random_Variable('model', values, probabilities)\n",
    "samples = model.sample(30)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
